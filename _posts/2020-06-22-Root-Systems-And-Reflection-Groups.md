---
title: 'Root Systems and Reflection Groups'
date: 2020-06-22
permalink: /posts/RootSystemsAndReflectionGroups/
tags:
  - Lie Algebras
  - Group Theory
---

I first came across the notion of root systems from [Humphreys](https://books.google.com/books/about/Introduction_to_Lie_Algebras_and_Represe.html?id=gCUlAQAAIAAJ). Leading up to that section, Humphreys presents the root space decomposition of a finite-dimensional semisimple Lie algebra, and at the end he notes some interesting properties that these roots have. These proeprties seem rather forced observatio a priori, but upon learning about the general theory of root systems, it becomes rather amazing that root systems do indeed arise in the theory of semisimple Lie algebras.

This connection between something as algebraic like Lie algebras with something as geometric and, to an extent, combinatorial like root systems has deep consequences. Namely, from classifying (reduced crystallographic) root systems, one can classify all possible simple Lie algebras; see [here](https://almosttrivial.github.io/posts/SimpleClassification/) for details.

However, root systems arise beyond just this classical study, appearing in more general constructions like affinization, superification, and quantization of Lie algebras. They also have deep connections to a family of groups known as Coxeter groups, and this is the perspective I plan on expanding upon here and in future blog posts. In particular, I will predominantly be following another book of [Humphreys](https://books.google.com/books/about/Reflection_Groups_and_Coxeter_Groups.html?id=ODfjmOeNLMUC).

The theory of root systems takes place in a real Euclidean space \\(V\\) equipped with a positive-definite symmetric bilinear form \\((\lambda,\mu)\\). In such a space, one can associate to any vector \\(\alpha\in V\\) the linear operator of **reflection** along \\(\alpha\\) i.e. the linear map

\begin{equation\*}
   s\_{\alpha}(\lambda) := \lambda - \frac{2(\lambda,\alpha)}{(\alpha,\alpha)}\alpha
\end{equation\*}

Note that this operator fixes pointwise every vector orthogonal to \\(\alpha\\) and send \\(\alpha\mapsto-\alpha\\). Moreover, this map is an orthogonal involution i.e.

\begin{equation\*}
   (s\_{\alpha}(\lambda),s\_{\alpha}(\mu)) = (\lambda,\mu),\quad\quad s\_{\alpha}^{2} = \text{id}
\end{equation\*}

We call a finite group generated by such simple reflections a **finite refletion group**. The reader is likely aware of at least the following family of finite reflection groups: the symmetric group on \\(n\\) letters! Indeed, there is a subgroup of orthogonal transformations on \\(\mathbb{R}^{n}\\) isomorphic to \\(S\_{n}\\). Namely, map each element of \\(S\_{n}\\) to the corresponding permutation on the coordinates; this clearly has an image in \\(O(V)\\) and is one-to-one. But the transposition \\((i,i +1)\\) generates \\(S\_{n}\\), hence their image in \\(O(V)\\) will also generate the image. If we denote a basis for \\(\mathbb{R}^{n}\\) by \\(\varepsilon\_{1},\dots,\varepsilon\_{n}\\), then the orthogonal transformation corresponding to \\((i,i + 1)\\) sends \\(\varepsilon\_{i} - \varepsilon\_{i+1}\\) to its negative, and fixes pointwise the corresponding hyperplane consisting of all vectors whose \\(i\\)-th and \\((i + 1)\\)-th coordinates are equal.

Now, the astute reader might be wondering what groups have to do with something I said would be more geometric and combinatorial. To this end, denote a finite reflection group by \\(W\\). Then recall that each simple reflection \\(s\_{\alpha}\\) fixes a hyperplane and reflects the line spanned by \(\alpha\\) orthogonal to it. Thus, each simple reflection determines such a line, and the marvelous thing is that the entire group \\(W\\) permutes these lines! That is

**Proposition** If \\(\phi\in O(V)\\) and \\(\alpha\in V\backslash\\{0\\}\\), then \\(\phi\circ s\_{\alpha}\circ\phi^{-1} = s\_{\phi(\alpha)}\\). In particular, if one takes \\(\phi \in W\\), then as a corollary \\(s\_{\phi(\alpha)}\in W\\) whenever \\(s\_{\alpha}\in W\\).

**Proof** In order to show \\(\phi\circ s\_{\alpha}\circ\phi^{-1} = s\_{\phi(\alpha)}\\) we must show that both sides map the same vector to the same image. To this end, consider \\(x\in H\_{\phi(\alpha)}\\), the hyperplane orthgonal to \\(\phi(\alpha)\\). For such an \\(x\\) we have \\(0 = (x,\phi(\alpha)) = (\phi^{-1}(x),\alpha)\\), where the second equality comes from the fact that \\(\phi\\) and hence \\(\phi^{-1}\\) are orthogonal. Then

\begin{equation\*}
   \phi\circ s\_{\alpha}\circ\phi^{-1}(x) = \phi(s\_{\alpha}(\phi^{-1}(x))) = \phi(\phi^{-1}(x)) = x = s\_{\phi(\alpha)}(x)
\end{equation\*}


